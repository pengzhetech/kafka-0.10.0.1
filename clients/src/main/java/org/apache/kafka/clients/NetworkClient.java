/**
 * Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE
 * file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file
 * to You under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the
 * License. You may obtain a copy of the License at
 * <p>
 * http://www.apache.org/licenses/LICENSE-2.0
 * <p>
 * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
 * an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
 * specific language governing permissions and limitations under the License.
 */
package org.apache.kafka.clients;

import org.apache.kafka.common.Cluster;
import org.apache.kafka.common.Node;
import org.apache.kafka.common.network.NetworkReceive;
import org.apache.kafka.common.network.Selectable;
import org.apache.kafka.common.network.Send;
import org.apache.kafka.common.protocol.ApiKeys;
import org.apache.kafka.common.protocol.Errors;
import org.apache.kafka.common.protocol.ProtoUtils;
import org.apache.kafka.common.protocol.types.Struct;
import org.apache.kafka.common.requests.MetadataRequest;
import org.apache.kafka.common.requests.MetadataResponse;
import org.apache.kafka.common.requests.RequestHeader;
import org.apache.kafka.common.requests.RequestSend;
import org.apache.kafka.common.requests.ResponseHeader;
import org.apache.kafka.common.utils.Time;
import org.apache.kafka.common.utils.Utils;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.IOException;
import java.net.InetSocketAddress;
import java.nio.ByteBuffer;
import java.util.ArrayList;
import java.util.List;
import java.util.Map;
import java.util.Random;

/**
 * A network client for asynchronous request/response network i/o. This is an internal class used to implement the
 * user-facing producer and consumer clients.
 * <p>
 * This class is not thread-safe!
 * <p>
 * NetworkClient是一个通用的网络客户端实现,不仅适用于生产者发送消息,也可以用于消费者消费消息以及服务端Broker之间的通信
 */
public class NetworkClient implements KafkaClient {

    private static final Logger log = LoggerFactory.getLogger(NetworkClient.class);

    /* the selector used to perform network i/o */
    /**
     * org.apache.kafka.common.network.Selector(KSelect)
     * 使用NIO非阻塞模式实现网络I/O操作,KSelect使用单独的一个线程可以管理多条网络上的连接,读,写操作
     */
    private final Selectable selector;

    private final MetadataUpdater metadataUpdater;

    private final Random randOffset;

    /* the state of each node's connection */
    private final ClusterConnectionStates connectionStates;

    /* the set of requests currently being sent or awaiting a response */
    private final InFlightRequests inFlightRequests;

    /* the socket send buffer size in bytes */
    private final int socketSendBuffer;

    /* the socket receive size buffer in bytes */
    private final int socketReceiveBuffer;

    /* the client id used to identify this client in requests to the server */
    private final String clientId;

    /* the current correlation id to use when sending requests to servers */
    private int correlation;

    /* max time in ms for the producer to wait for acknowledgement from server*/
    private final int requestTimeoutMs;

    private final Time time;

    public NetworkClient(Selectable selector,
                         Metadata metadata,
                         String clientId,
                         int maxInFlightRequestsPerConnection,
                         long reconnectBackoffMs,
                         int socketSendBuffer,
                         int socketReceiveBuffer,
                         int requestTimeoutMs,
                         Time time) {
        this(null, metadata, selector, clientId, maxInFlightRequestsPerConnection,
                reconnectBackoffMs, socketSendBuffer, socketReceiveBuffer, requestTimeoutMs, time);
    }

    public NetworkClient(Selectable selector,
                         MetadataUpdater metadataUpdater,
                         String clientId,
                         int maxInFlightRequestsPerConnection,
                         long reconnectBackoffMs,
                         int socketSendBuffer,
                         int socketReceiveBuffer,
                         int requestTimeoutMs,
                         Time time) {
        this(metadataUpdater, null, selector, clientId, maxInFlightRequestsPerConnection, reconnectBackoffMs,
                socketSendBuffer, socketReceiveBuffer, requestTimeoutMs, time);
    }

    private NetworkClient(MetadataUpdater metadataUpdater,
                          Metadata metadata,
                          Selectable selector,
                          String clientId,
                          int maxInFlightRequestsPerConnection,
                          long reconnectBackoffMs,
                          int socketSendBuffer,
                          int socketReceiveBuffer,
                          int requestTimeoutMs,
                          Time time) {

        /* It would be better if we could pass `DefaultMetadataUpdater` from the public constructor, but it's not
         * possible because `DefaultMetadataUpdater` is an inner class and it can only be instantiated after the
         * super constructor is invoked.
         */
        if (metadataUpdater == null) {
            if (metadata == null)
                throw new IllegalArgumentException("`metadata` must not be null");
            this.metadataUpdater = new DefaultMetadataUpdater(metadata);
        } else {
            this.metadataUpdater = metadataUpdater;
        }
        this.selector = selector;
        this.clientId = clientId;
        this.inFlightRequests = new InFlightRequests(maxInFlightRequestsPerConnection);
        this.connectionStates = new ClusterConnectionStates(reconnectBackoffMs);
        this.socketSendBuffer = socketSendBuffer;
        this.socketReceiveBuffer = socketReceiveBuffer;
        this.correlation = 0;
        this.randOffset = new Random();
        this.requestTimeoutMs = requestTimeoutMs;
        this.time = time;
    }

    /**
     * Begin connecting to the given node, return true if we are already connected and ready to send to that node.
     * <p>
     * NetworkClient.ready()方法用来检测Node是否准备好接受数据.
     * 首先通过NetworkClient.isReady()方法检查是否可以向一个Node发送请求,需要符合下面三个条件,则表示Node已经准备好
     * 1):Metadata并未处于更新或需要更新的状态
     * 2):已经成功建立连接且连接正常,connectionStates.isConnected(node)
     * 3):InFlightRequest.canSendMore()返回true
     * <p>
     * 如果NetworkClient.isReady()方法返回false,则满足下面两个条件,则会调用initiateConnect()方法发起连接
     * 1):连接不能是CONNECTING状态,必须是DISCONNECTED
     * 2):为了避免网络拥塞,重连不能太频繁,两次重试之间的时间差必须大于重试的避退时间,由reconnectBackOffMs指定
     * <p>
     * NetworkClient.initiateConnect()方法会修改在ClusterConnectionStates中的连接状态
     * 并调用Selector.connect()方法发起连接,之后调用Selector.pollSelectionKeys()方法时,
     * 判断连接是否建立,如果建立成功,则会将ConnectionState设置为CONNECTED
     *
     * @param node The node to check
     * @param now  The current timestamp
     * @return True if we are ready to send to the given node
     */
    @Override
    public boolean ready(Node node, long now) {
        if (node.isEmpty())
            throw new IllegalArgumentException("Cannot connect to empty node " + node);

        if (isReady(node, now))
            return true;

        if (connectionStates.canConnect(node.idString(), now))
            // if we are interested in sending to a node and we don't have a connection to it, initiate one
            initiateConnect(node, now);

        return false;
    }

    /**
     * Closes the connection to a particular node (if there is one).
     *
     * @param nodeId The id of the node
     */
    @Override
    public void close(String nodeId) {
        selector.close(nodeId);
        for (ClientRequest request : inFlightRequests.clearAll(nodeId))
            metadataUpdater.maybeHandleDisconnection(request);
        connectionStates.remove(nodeId);
    }

    /**
     * Returns the number of milliseconds to wait, based on the connection state, before attempting to send data. When
     * disconnected, this respects the reconnect backoff time. When connecting or connected, this handles slow/stalled
     * connections.
     *
     * @param node The node to check
     * @param now  The current timestamp
     * @return The number of milliseconds to wait.
     */
    @Override
    public long connectionDelay(Node node, long now) {
        return connectionStates.connectionDelay(node.idString(), now);
    }

    /**
     * Check if the connection of the node has failed, based on the connection state. Such connection failure are
     * usually transient and can be resumed in the next {@link #ready(org.apache.kafka.common.Node, long)} }
     * call, but there are cases where transient failures needs to be caught and re-acted upon.
     *
     * @param node the node to check
     * @return true iff the connection has failed and the node is disconnected
     */
    @Override
    public boolean connectionFailed(Node node) {
        return connectionStates.connectionState(node.idString()).equals(ConnectionState.DISCONNECTED);
    }

    /**
     * Check if the node with the given id is ready to send more requests.
     *
     * @param node The node
     * @param now  The current time in ms
     * @return true if the node is ready
     */
    @Override
    public boolean isReady(Node node, long now) {
        // if we need to update our metadata now declare all requests unready to make metadata requests first
        // priority
        return !metadataUpdater.isUpdateDue(now) && canSendRequest(node.idString());
    }

    /**
     * Are we connected and ready and able to send more requests to the given connection?
     *
     * @param node The node
     */
    private boolean canSendRequest(String node) {
        //检测网络状态,检测网络协议正常且是否通过了身份验证
        return connectionStates.isConnected(node) && selector.isChannelReady(node) && inFlightRequests.canSendMore(node);
    }

    /**
     * Queue up the given request for sending. Requests can only be sent out to ready nodes.
     * <p>
     * NetworkClient.send()方法主要是将请求设置到KafkaChannel.send字段中,同时将请求添加到InFlightRequests队列中等待响应
     *
     * @param request The request
     * @param now     The current timestamp
     */
    @Override
    public void send(ClientRequest request, long now) {
        String nodeId = request.request().destination();
        //检测是否能够向指定Node发送请求
        if (!canSendRequest(nodeId))
            throw new IllegalStateException("Attempt to send a request to node " + nodeId + " which is not ready.");
        //设置KafkaChannel.send字段,并将请求放入InFlightRequests队列中等待响应
        doSend(request, now);
    }

    private void doSend(ClientRequest request, long now) {
        request.setSendTimeMs(now);
        //将请求添加到inFlightRequests队列中等待响应
        this.inFlightRequests.add(request);
        selector.send(request.request());
    }

    /**
     * Do actual reads and writes to sockets.
     * <p>
     * NetworkClient.poll()方法调用KSelector.poll()方法进行网络I/O
     * 并使用handle*方法对KSelector.poll()产生的各种数据和队列进行处理
     *
     * @param timeout The maximum amount of time to wait (in ms) for responses if there are none immediately,
     *                must be non-negative. The actual timeout will be the minimum of timeout, request timeout and
     *                metadata timeout
     * @param now     The current time in milliseconds
     * @return The list of responses received
     */
    @Override
    public List<ClientResponse> poll(long timeout, long now) {
        //更新metadata
        long metadataTimeout = metadataUpdater.maybeUpdate(now);
        try {
            //执行I/O操作
            this.selector.poll(Utils.min(timeout, metadataTimeout, requestTimeoutMs));
        } catch (IOException e) {
            log.error("Unexpected error during I/O", e);
        }

        // process completed actions
        long updatedNow = this.time.milliseconds();
        //响应队列
        List<ClientResponse> responses = new ArrayList<>();
        //处理completeSends队列
        handleCompletedSends(responses, updatedNow);
        //处理completeReceive队列
        handleCompletedReceives(responses, updatedNow);
        //处理disconnected列表
        handleDisconnections(responses, updatedNow);
        //处理connected列表
        handleConnections();
        //处理InFlightRequests中超时的请求
        handleTimedOutRequests(responses, updatedNow);

        // invoke callbacks
        //循环调用ClientRequest的回调函数
        for (ClientResponse response : responses) {
            if (response.request().hasCallback()) {
                try {
                    //这个Callback会调用Sender.handleProduceResponse()方法
                    response.request().callback().onComplete(response);
                } catch (Exception e) {
                    log.error("Uncaught error in request completion:", e);
                }
            }
        }

        return responses;
    }

    /**
     * Get the number of in-flight requests
     */
    @Override
    public int inFlightRequestCount() {
        return this.inFlightRequests.inFlightRequestCount();
    }

    /**
     * Get the number of in-flight requests for a given node
     */
    @Override
    public int inFlightRequestCount(String node) {
        return this.inFlightRequests.inFlightRequestCount(node);
    }

    /**
     * Generate a request header for the given API key
     *
     * @param key The api key
     * @return A request header with the appropriate client id and correlation id
     */
    @Override
    public RequestHeader nextRequestHeader(ApiKeys key) {
        return new RequestHeader(key.id, clientId, correlation++);
    }

    /**
     * Generate a request header for the given API key and version
     *
     * @param key     The api key
     * @param version The api version
     * @return A request header with the appropriate client id and correlation id
     */
    @Override
    public RequestHeader nextRequestHeader(ApiKeys key, short version) {
        return new RequestHeader(key.id, version, clientId, correlation++);
    }

    /**
     * Interrupt the client if it is blocked waiting on I/O.
     */
    @Override
    public void wakeup() {
        this.selector.wakeup();
    }

    /**
     * Close the network client
     */
    @Override
    public void close() {
        this.selector.close();
    }

    /**
     * Choose the node with the fewest outstanding requests which is at least eligible for connection. This method will
     * prefer a node with an existing connection, but will potentially choose a node for which we don't yet have a
     * connection if all existing connections are in use. This method will never choose a node for which there is no
     * existing connection and from which we have disconnected within the reconnect backoff period.
     *
     * @return The node with the fewest in-flight requests.
     */
    @Override
    public Node leastLoadedNode(long now) {
        List<Node> nodes = this.metadataUpdater.fetchNodes();
        int inflight = Integer.MAX_VALUE;
        Node found = null;

        int offset = this.randOffset.nextInt(nodes.size());
        for (int i = 0; i < nodes.size(); i++) {
            int idx = (offset + i) % nodes.size();
            Node node = nodes.get(idx);
            int currInflight = this.inFlightRequests.inFlightRequestCount(node.idString());
            if (currInflight == 0 && this.connectionStates.isConnected(node.idString())) {
                // if we find an established connection with no in-flight requests we can stop right away
                return node;
            } else if (!this.connectionStates.isBlackedOut(node.idString(), now) && currInflight < inflight) {
                // otherwise if this is the best we have found so far, record that
                inflight = currInflight;
                found = node;
            }
        }

        return found;
    }

    public static Struct parseResponse(ByteBuffer responseBuffer, RequestHeader requestHeader) {
        ResponseHeader responseHeader = ResponseHeader.parse(responseBuffer);
        // Always expect the response version id to be the same as the request version id
        short apiKey = requestHeader.apiKey();
        short apiVer = requestHeader.apiVersion();
        Struct responseBody = ProtoUtils.responseSchema(apiKey, apiVer).read(responseBuffer);
        correlate(requestHeader, responseHeader);
        return responseBody;
    }

    /**
     * Post process disconnection of a node
     *
     * @param responses The list of responses to update
     * @param nodeId    Id of the node to be disconnected
     * @param now       The current time
     */
    private void processDisconnection(List<ClientResponse> responses, String nodeId, long now) {
        //更新连接状态
        connectionStates.disconnected(nodeId, now);
        for (ClientRequest request : this.inFlightRequests.clearAll(nodeId)) {
            log.trace("Cancelled request {} due to node {} being disconnected", request, nodeId);
            //调用metadataUpdater.maybeHandleDisconnection()方法处理MetadataRequest
            if (!metadataUpdater.maybeHandleDisconnection(request))
            /**
             * 如果不是MetadataRequest,则创建ClientResponse并添加到responses集合中,第三个参数表示连接是否断开
             */
                responses.add(new ClientResponse(request, now, true, null));
        }
    }

    /**
     * Iterate over all the inflight requests and expire any requests that have exceeded the configured requestTimeout.
     * The connection to the node associated with the request will be terminated and will be treated as a disconnection.
     * <p>
     * 遍历inFlightRequests集合,获取有超时请求的Node集合,之后的处理逻辑与handleDisconnections()一样
     *
     * @param responses The list of responses to update
     * @param now       The current time
     */
    private void handleTimedOutRequests(List<ClientResponse> responses, long now) {
        List<String> nodeIds = this.inFlightRequests.getNodesWithTimedOutRequests(now, this.requestTimeoutMs);
        for (String nodeId : nodeIds) {
            // close connection to the node
            this.selector.close(nodeId);
            log.debug("Disconnecting from node {} due to request timeout.", nodeId);
            processDisconnection(responses, nodeId, now);
        }

        // we disconnected, so we should probably refresh our metadata
        if (nodeIds.size() > 0)
            metadataUpdater.requestUpdate();
    }

    /**
     * Handle any completed request send. In particular if no response is expected consider the request complete.
     * <p>
     * 首先,InFlightRequests保存的是已发送但没有收到响应的请求,completedSends保存的是最近一次poll()方法发送成功的请求,
     * 所以completedSends列表与InFlightRequests中对应队列的最后一个请求应该是一致的
     * handleCompletedSends方法会遍历completedSends,如果发现不需要响应的请求,则将其从inFlightRequests中删除
     * 并向responses列表中添加对应的ClientResponse
     * 在ClientResponse中包含一个指向ClientRequest的引用
     *
     * @param responses The list of responses to update
     * @param now       The current time
     */
    private void handleCompletedSends(List<ClientResponse> responses, long now) {
        // if no response is expected then when the send is completed, return it
        //遍历completedSends
        for (Send send : this.selector.completedSends()) {
            //获取指定队列的第一个元素
            ClientRequest request = this.inFlightRequests.lastSent(send.destination());
            //检测请求是否需要响应
            if (!request.expectResponse()) {
                //将inFlightRequests中对应队列中的第一个元素删除
                this.inFlightRequests.completeLastSent(send.destination());
                //生产ClientResponse对象,添加到responses集合
                responses.add(new ClientResponse(request, now, false, null));
            }
        }
    }

    /**
     * Handle any completed receives and update the response list with the responses received.
     * <p>
     * 遍历completedReceives队列,并在inFlightRequests中删除对应的ClientRequest,并向responses列表中添加对应的ClientResponse
     * 如果是Metadata更新请求的响应,则会调用MetadataUpdater.maybeHandleCompletedReceive()方法,
     * 更新Metadata中记录的kafka集群元数据
     *
     * @param responses The list of responses to update
     * @param now       The current time
     */
    private void handleCompletedReceives(List<ClientResponse> responses, long now) {
        for (NetworkReceive receive : this.selector.completedReceives()) {
            //获取返回响应的NodeId
            String source = receive.source();
            //从inFlightRequests中取出对应的ClientRequest
            ClientRequest req = inFlightRequests.completeNext(source);
            //解析响应
            Struct body = parseResponse(receive.payload(), req.request().header());
            //调用maybeHandleCompletedReceive处理Metadata
            //其中会更新Metadata中记录的集群元数据,并唤醒所有等待Metadata更新完成的线程
            if (!metadataUpdater.maybeHandleCompletedReceive(req, now, body))
                //如果不是MetadataResponse响应,则创建ClientResponse添加到responses集合中
                responses.add(new ClientResponse(req, now, false, body));
        }
    }

    /**
     * Handle any disconnected connections
     * <p>
     * 遍历disconnected列表,将inFlightRequests对应节点的ClientRequest清空,对每个请求都创建ClientResponse并添加到responses列表中
     * 这里创建的ClientResponse会标识此响应并不是服务端返回的正常响应,而是因为连接断开而产生的,如果是Metadata更新请求的响应
     * 则会调用metadataUpdater.maybeHandleDisconnection()方法处理,最后将Metadata.needUpdate设置为true
     * 标识需要更新集群元数据
     *
     * @param responses The list of responses that completed with the disconnection
     * @param now       The current time
     */
    private void handleDisconnections(List<ClientResponse> responses, long now) {
        //更新连接状态,并清理掉inFlightRequests中华断开连接的Node与对应的ClientRequest
        for (String node : this.selector.disconnected()) {
            log.debug("Node {} disconnected.", node);
            processDisconnection(responses, node, now);
        }
        // we got a disconnect so we should probably refresh our metadata and see if that broker is dead
        if (this.selector.disconnected().size() > 0)
            //标识需要更新集群元数据
            metadataUpdater.requestUpdate();
    }

    /**
     * Record any newly completed connections
     * 遍历connected列表,将connectionStates中记录的连接状态改为CONNECTED
     */
    private void handleConnections() {
        for (String node : this.selector.connected()) {
            log.debug("Completed connection to node {}", node);
            this.connectionStates.connected(node);
        }
    }

    /**
     * Validate that the response corresponds to the request we expect or else explode
     */
    private static void correlate(RequestHeader requestHeader, ResponseHeader responseHeader) {
        if (requestHeader.correlationId() != responseHeader.correlationId())
            throw new IllegalStateException("Correlation id for response (" + responseHeader.correlationId()
                    + ") does not match request (" + requestHeader.correlationId() + ")");
    }

    /**
     * Initiate a connection to the given node
     */
    private void initiateConnect(Node node, long now) {
        String nodeConnectionId = node.idString();
        try {
            log.debug("Initiating connection to node {} at {}:{}.", node.id(), node.host(), node.port());
            this.connectionStates.connecting(nodeConnectionId, now);
            selector.connect(nodeConnectionId,
                    new InetSocketAddress(node.host(), node.port()),
                    this.socketSendBuffer,
                    this.socketReceiveBuffer);
        } catch (IOException e) {
            /* attempt failed, we'll try again after the backoff */
            connectionStates.disconnected(nodeConnectionId, now);
            /* maybe the problem is our metadata, update it */
            metadataUpdater.requestUpdate();
            log.debug("Error connecting to node {} at {}:{}:", node.id(), node.host(), node.port(), e);
        }
    }

    class DefaultMetadataUpdater implements MetadataUpdater {

        /* the current cluster metadata */
        /**
         * 指向记录了集群元数据的Metadata对象
         */
        private final Metadata metadata;

        /* true iff there is a metadata request that has been sent and for which we have not yet received a response */
        /**
         * 用来标识是否已经发送了MetadataRequest请求更新Metadata,如果已经发送,则没有必要再重复发送
         */
        private boolean metadataFetchInProgress;

        /* the last timestamp when no broker node is available to connect */
        /**
         * 当检测到没有可用节点时,则会用此字段记录时间戳
         */
        private long lastNoNodeAvailableMs;

        DefaultMetadataUpdater(Metadata metadata) {
            this.metadata = metadata;
            this.metadataFetchInProgress = false;
            this.lastNoNodeAvailableMs = 0;
        }

        @Override
        public List<Node> fetchNodes() {
            return metadata.fetch().nodes();
        }

        @Override
        public boolean isUpdateDue(long now) {
            return !this.metadataFetchInProgress && this.metadata.timeToNextUpdate(now) == 0;
        }

        /**
         * @param now
         * @return maybeUpdate()方法是DefaultMetadataUpdater的核心方法, 用来判断当前的Metadata中保存的集群元数据是否需要更新
         * 首先检测metadataFetchInProgress字段,如果没发送,满足下列任一条件即可:
         * 1):Metadata.needUpdate字段被设置为true
         * 2):长时间没更新,默认是每5分钟更新一次
         * <p>
         * 如果需要更新,则发送MetadataRequest请求
         * MetadataRequest请求的格式比较简单,其消息头部包含ApiKeys.METADATA标识
         * 消息体包含Topic集合表示需要获取元数据的Topic,如果Topic为null,则表示请求全部Topic的元数据
         * <p>
         * MetadataRequest发送请求之前,要将metadataFetchInProgress置位true,然后从所有Node中选择负载最小的Node节点
         * 向其发送请求,这里的负载大小是通过每个Node在InFlightRequest队列中未确认的请求决定的,未确认的请求越多,则认为负载越大
         * 剩余的步骤与普通请求的方式一样,先将请求添加到InFlightRequests队列中,然后设置到kafkaChannel的send字段中
         * 通过KSeletor.poll()方法将MetaRequest请求发送出去
         */
        @Override
        public long maybeUpdate(long now) {
            // should we update our metadata?
            /**
             * 调用Metadata.timeToNextUpdate()方法,其中会检测needUpdate的值,避退时间,是否长时间未更新
             * 最终得到下一次更新集群元数据的时间戳
             */
            long timeToNextMetadataUpdate = metadata.timeToNextUpdate(now);
            //获取下一次尝试重新连接服务端的时间戳
            long timeToNextReconnectAttempt = Math.max(this.lastNoNodeAvailableMs + metadata.refreshBackoff() - now, 0);
            //检测是否已经发送了MetadataRequest请求
            long waitForMetadataFetch = this.metadataFetchInProgress ? Integer.MAX_VALUE : 0;
            // if there is no node available to connect, back off refreshing metadata
            //计算当前距离下次可以发送MetadataRequest请求的时间差
            long metadataTimeout = Math.max(Math.max(timeToNextMetadataUpdate, timeToNextReconnectAttempt),
                    waitForMetadataFetch);

            if (metadataTimeout == 0) {
                //允许发送MetadataRequest请求
                // Beware that the behavior of this method and the computation of timeouts for poll() are
                // highly dependent on the behavior of leastLoadedNode.
                //找到负载最小的Node,若没有node,则返回null
                Node node = leastLoadedNode(now);
                //创建并缓存MetadataRequest,等待下次poll()方法才会真正发送
                maybeUpdate(now, node);
            }

            return metadataTimeout;
        }

        /**
         * 当连接断开,或其他异常导致无法获取响应时,由maybeHandleDisconnection()方法处理
         * 将metadataFetchInProgress置为false,这样就可以顺利发送下一次更新Metadata请求了
         *
         * @param request
         * @return
         */
        @Override
        public boolean maybeHandleDisconnection(ClientRequest request) {
            ApiKeys requestKey = ApiKeys.forId(request.request().header().apiKey());
            //检测是否为MetadataRequest请求
            if (requestKey == ApiKeys.METADATA) {
                Cluster cluster = metadata.fetch();
                if (cluster.isBootstrapConfigured()) {
                    int nodeId = Integer.parseInt(request.request().destination());
                    Node node = cluster.nodeById(nodeId);
                    if (node != null)
                        log.warn("Bootstrap broker {}:{} disconnected", node.host(), node.port());
                }

                metadataFetchInProgress = false;
                return true;
            }

            return false;
        }

        /**
         * @param req
         * @param now
         * @param body
         * @return 在收到MetadataResponse后, 会先调用MetadataUpdater.maybeHandleCompletedReceive方法
         * 检测是否为MetadataResponse,如果是则调用handleResponse()方法解析响应,并构造Cluster对象更新
         * Cluster.cluster字段,注意Cluster是不可变对象,所以更新集群元数据的方式是:创建新的Cluster对象,覆盖Cluster.cluster字段
         */
        @Override
        public boolean maybeHandleCompletedReceive(ClientRequest req, long now, Struct body) {
            short apiKey = req.request().header().apiKey();
            //检测是否为MetadataRequest请求
            if (apiKey == ApiKeys.METADATA.id && req.isInitiatedByNetworkClient()) {
                handleResponse(req.request().header(), body, now);
                return true;
            }
            return false;
        }

        @Override
        public void requestUpdate() {
            this.metadata.requestUpdate();
        }

        private void handleResponse(RequestHeader header, Struct body, long now) {
            //修改metadataFetchInProgress
            this.metadataFetchInProgress = false;
            //解析MetadataResponse
            MetadataResponse response = new MetadataResponse(body);
            //创建Cluster对
            Cluster cluster = response.cluster();
            // check if any topics metadata failed to get updated
            //检测MetadataResponse中的错误码
            Map<String, Errors> errors = response.errors();
            if (!errors.isEmpty())
                log.warn("Error while fetching metadata with correlation id {} : {}", header.correlationId(), errors);

            // don't update the cluster if there are no valid nodes...the topic we want may still be in the process of being
            // created which means we will get errors and no nodes until it exists
            if (cluster.nodes().size() > 0) {
                //在Metadata.update()方法中,首先通知Metadata上的监听器,之后更新cluster字段,
                // 最后唤醒等待Metadata更新完成的线程
                this.metadata.update(cluster, now);
            } else {
                log.trace("Ignoring empty metadata response with correlation id {}.", header.correlationId());
                //更新metadata失败,只是更新lastRefreshMs字段
                this.metadata.failedUpdate(now);
            }
        }

        /**
         * Create a metadata request for the given topics
         */
        private ClientRequest request(long now, String node, MetadataRequest metadata) {
            RequestSend send = new RequestSend(node, nextRequestHeader(ApiKeys.METADATA), metadata.toStruct());
            return new ClientRequest(now, true, send, null, true);
        }

        /**
         * Add a metadata request to the list of sends if we can make one
         */
        private void maybeUpdate(long now, Node node) {
            if (node == null) {
                //检测是否有Node可用
                log.debug("Give up sending metadata request since no node is available");
                // mark the timestamp for no node available to connect
                //设置lastNoNodeAvailableMs
                this.lastNoNodeAvailableMs = now;
                return;
            }
            String nodeConnectionId = node.idString();
            //检测是否允许向此Node发送请求
            if (canSendRequest(nodeConnectionId)) {
                this.metadataFetchInProgress = true;
                MetadataRequest metadataRequest;
                //指定需要更新元数据的Topic
                if (metadata.needMetadataForAllTopics())
                    metadataRequest = MetadataRequest.allTopics();
                else
                    metadataRequest = new MetadataRequest(new ArrayList<>(metadata.topics()));
                //将MetadataRequest封装成ClientRequest
                ClientRequest clientRequest = request(now, nodeConnectionId, metadataRequest);
                log.debug("Sending metadata request {} to node {}", metadataRequest, node.id());
                //缓存请求,在下次poll()方法操作中会将其发送出去
                doSend(clientRequest, now);
            } else if (connectionStates.canConnect(nodeConnectionId, now)) {
                // we don't have a connection to this node right now, make one
                log.debug("Initialize connection to node {} for sending metadata request", node.id());
                //初始化连接
                initiateConnect(node, now);
                // If initiateConnect failed immediately, this node will be put into blackout and we
                // should allow immediately retrying in case there is another candidate node. If it
                // is still connecting, the worst case is that we end up setting a longer timeout
                // on the next round and then wait for the response.
            } else { // connected, but can't send more OR connecting
                // In either case, we just need to wait for a network event to let us know the selected
                // connection might be usable again.
                //已成功连接到指定节点,但不能发送请求,则更新lastNoNodeAvailableMs后等待
                this.lastNoNodeAvailableMs = now;
            }
        }

    }

}
